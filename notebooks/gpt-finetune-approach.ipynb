{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LTVs7hdJgKal","executionInfo":{"status":"ok","timestamp":1666575135875,"user_tz":240,"elapsed":19105,"user":{"displayName":"Ken Trinh","userId":"00929063106744050420"}},"outputId":"9d738589-c392-4821-98ed-9747ad6d9c23"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"oXV3Ld3KgKap"},"source":["# GPT Fine Tuning\n","Since lyric generation task primarily deals with generating the next word using context from the previous word as input. A decoder based transformer would work well for this. However, since GPT is trained on a large corpus of data. We will be perfomring some fine tuning using our lyrical data before it is ready to use for lyric generation. [Fine-Tune-GPT-article](https://towardsdatascience.com/how-to-fine-tune-gpt-2-for-text-generation-ae2ea53bc272)"]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3uqcZQQhpnOb","executionInfo":{"status":"ok","timestamp":1666575146566,"user_tz":240,"elapsed":10695,"user":{"displayName":"Ken Trinh","userId":"00929063106744050420"}},"outputId":"962854ee-61c8-4b67-a9d6-f29bec67469f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\n","\u001b[K     |████████████████████████████████| 5.3 MB 36.2 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n","\u001b[K     |████████████████████████████████| 163 kB 47.2 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 52.9 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.9.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.1 transformers-4.23.1\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z06cyC2KgKar"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LjSz5Nc8gKas","executionInfo":{"status":"ok","timestamp":1666575152552,"user_tz":240,"elapsed":5,"user":{"displayName":"Ken Trinh","userId":"00929063106744050420"}},"outputId":"4ad4c7dd-30d2-4985-da0d-dfbab9e19f5c"},"outputs":[{"output_type":"stream","name":"stdout","text":["[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"]}],"source":["DATA_DIR = \"/content/drive/MyDrive/w266-finalproj/data\"\n","print(tf.config.list_physical_devices('GPU'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V6NTR4bFgKat"},"outputs":[],"source":["# load the data \n","# from a sample of 6000 pop lyrics, let's use 2000 for fine tuning task\n","# the rest will be use for training a decoder layer\n","pop_data = pd.read_csv(f\"{DATA_DIR}/02_intermediate/rock_sample.csv\")\n","pop_data = pop_data.loc[:, ~pop_data.columns.str.contains('^Unnamed')]\n","\n","# sampling data without replacement so the datasets do not mixed together\n","# fine_tuning_set = pop_data.sample(n=2000, replace=False)\n","# generation_set = pop_data.drop(fine_tuning_set.index)\n","fine_tuning_set = pop_data"]},{"cell_type":"markdown","metadata":{"id":"xUEzXSjJgKau"},"source":["## Data Preprocessing\n","A quick look at the lyrics, the data is a little dirty. We will need to do some preprocessing before it is ready to use. The following pre-processing procedures will be apply:\n","1. removal of odds tokens\n","2. tokenization"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":130,"referenced_widgets":["86f95a77c59545b4a5556c49a2cddab3","6132c7cd8b0d431d8675ca6fcbaf72b1","aaf72408d7ce48fda2447ce011ba6804","51a6b9e3f7004971977e5f9388e8d6c9","dae77d0d6d39418c9621840ce135cff6","34533ab31ff3434a9d6d3558fa10844f","28271993500a4d3d86ad9fdf9e2183b1","58cdf13c382843eab2ea8e45be6fd3f7","b15b060f85d441ee8ddd5e267cb87b88","efbb0938816b46589c4584c9c96c3701","46da04d5a1914892880a1171cad35d6c","ad57e99e8ac34fa69e1e7fc06f21ad2c","a5bcaa9b6e4443fcb583873309932e11","17a2fca0645d465d99ce566d241c2b9f","6af301a7a192414784d057d8a580c29d","8f97bc4de6ce4c4285700d98d43f41e4","035b7c045ea04c9fb15417c059d61d60","2a0632c06de3447ba39fad06e712c411","4214f19e99854b90b6a2f9da2bd09f62","1303d09edaf64c02877bd3d98369c676","afbb87143cf84f1dbe90836db691d563","f348b3a299334523a88265750eadb03d","ac493df79acf47fb813030761096e053","17f2b2ec48bc4902afe1329fffe8c31f","903f290e886741bd9c7cb73fe188a140","e1c9d8b37a9346149bfad9c80c7361e2","1a9d61b7e0ab4e97a118e5e08b9ce0b7","072ea81e085d4c69970876d22e7ba408","56ef7dc40952420c91653a2e23093743","ebece051889a48168e3e85a506bcf4b1","f424a724b24044a6b6f1281b6b637d1c","4de79b0fa1dd4e64bec76466cb074769","ac4d22fce3bf4039844fcd455e86df7f"]},"id":"hXz7OJAmgKav","executionInfo":{"status":"ok","timestamp":1666575191745,"user_tz":240,"elapsed":36516,"user":{"displayName":"Ken Trinh","userId":"00929063106744050420"}},"outputId":"d800039b-4670-4d2d-c195-a38e9c0502e8"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86f95a77c59545b4a5556c49a2cddab3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad57e99e8ac34fa69e1e7fc06f21ad2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac493df79acf47fb813030761096e053"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Number of Lyrics: 6000\n"]}],"source":["class SongLyrics(Dataset):\n","    def __init__(self, data, truncate=False, gpt2_type=\"gpt2\", max_length=1024):\n","        \"\"\"\n","            Clean up and Tokenize the given lyric\n","            Parameters\n","            ----------\n","            data : pd.Series()\n","                lyrics data in series format\n","\n","            target_col : { boolean, default: False }\n","                toggle to truncate the list of tokenized lyric to a desirable length\n","\n","            gpt2_type : { string, default: \"gpt2\" }\n","                numerical seed for random state of resampling\n","\n","            max_length : { int, default=1024 },\n","                maximum length of the given dataset\n","\n","            Returns\n","            ----------\n","            SongLyric : Object\n","                contains the treated lyrics using specified tokenizer\n","            \n","        \"\"\"\n","        self.tokenizer = GPT2Tokenizer.from_pretrained(gpt2_type)\n","        self.lyrics = []\n","        \n","        for row in data:\n","            row = row.replace('\\n\\n', ' ')\n","            row = row.replace('\\n', ' ')\n","            row = row.replace('\\t', ' ')\n","            row = row.replace('#', ' ')\n","            row = row.replace(\"'\", '')\n","            row = row.replace(\"(\", '')\n","            row = row.replace(\")\", '')\n","            row = row.replace(\";\", '')\n","            row = row.replace(\":\", '')\n","            row = row.replace(\"-\", '')\n","            row = row.replace(\"[\", '')\n","            row = row.replace(\"]\", '')\n","            self.lyrics.append(torch.tensor(\n","                self.tokenizer.encode(f\"<|{data}|>{row[:max_length]}<|endoftext|>\", \n","                                      truncation=True,\n","                                      max_length=max_length)\n","            ))\n","            \n","        if truncate:\n","            self.lyrics = self.lyrics[:20000]\n","        self.lyrics_count = len(self.lyrics)\n","        \n","    def __len__(self):\n","        return self.lyrics_count\n","\n","    def __getitem__(self, item):\n","        return self.lyrics[item]\n","\n","# # clean up the input text\n","# # tokenize the dataset\n","dataset = SongLyrics(pop_data['lyrics'], truncate=True, gpt2_type=\"gpt2\", max_length=1024)\n","print(f\"Number of Lyrics: {len(dataset)}\")"]},{"cell_type":"markdown","metadata":{"id":"NJZquSHZgKaw"},"source":["## Pretraining Task\n","Preparing GPT to perform pretraining task. Since GPT2 is big, we'll most likely run into some memory errors. To remedy this issue, we'll be using an accumulate gradient technqiue outlined in [Fine-Tune-GPT-article](https://towardsdatascience.com/how-to-fine-tune-gpt-2-for-text-generation-ae2ea53bc272). Quote from the article, \"the idea is before calling for optimization to perform a step of graident descent, it will sum the gradients of several operations. Then it will divide that total by the number of accumulated steps in otder to get an average loss over the training sample.\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5-uLjYVlgKax","executionInfo":{"status":"ok","timestamp":1666575206064,"user_tz":240,"elapsed":14322,"user":{"displayName":"Ken Trinh","userId":"00929063106744050420"}},"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["b4d4e0a33e224d7fac7a603dd37a8d0a","888ae0a7457a4fb88781d12ce7aaa741","1bbaa6d9af16448fbdf781b9b579d344","8d23123002f3434f8cb1bf65c58ef5f4","931d6dc37d30427592027507427ebc94","fe562c0e057c44169946ef6ca8e96b54","d3dce55bf3084f46be1e24ff05eb99dd","ad04e65a80034eaebf71d850fffc84a2","84c189d7fd5e4d30b33e4ed381c370b2","6a073af9e77045d18b78c4cc91d9e4b6","ac5425b949924c54ba8a360ddf3603b8"]},"outputId":"c3f058e4-9bec-4516-d7d6-9b0cfa1ee54f"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/548M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4d4e0a33e224d7fac7a603dd37a8d0a"}},"metadata":{}}],"source":["tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","model = GPT2LMHeadModel.from_pretrained('gpt2')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8uy8_qtOgKay"},"outputs":[],"source":["def pack_tensor(new_tensor, packed_tensor, max_seq_len):\n","    \"\"\"\n","        Accumulated batch size (since GPT2 is so big)\n","    \"\"\"\n","    if packed_tensor is None:\n","        return new_tensor, True, None\n","    if new_tensor.size()[1] + packed_tensor.size()[1] > max_seq_len:\n","        return packed_tensor, False, new_tensor\n","    else:\n","        packed_tensor = torch.cat([new_tensor, packed_tensor[:, 1:]], dim=1)\n","        return packed_tensor, True, None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8JIQN6mGgKay"},"outputs":[],"source":["def train( \n","    dataset, model, tokenizer,\n","    batch_size=24, epochs=20, lr=2e-5,\n","    max_seq_len=400, warmup_steps=200,\n","    gpt2_type=\"gpt2\", output_dir=\".\", output_prefix=\"wreckgar\",\n","    test_mode=False,save_model_on_epoch=False,\n","):\n","\n","    acc_steps = 100\n","    device=torch.device(\"cuda\")\n","    model = model.cuda()\n","    model.train()\n","\n","    optimizer = AdamW(model.parameters(), lr=lr)\n","    scheduler = get_linear_schedule_with_warmup(\n","        optimizer, num_warmup_steps=warmup_steps, num_training_steps=-1\n","    )\n","\n","    train_dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n","    loss=0\n","    accumulating_batch_count = 0\n","    input_tensor = None\n","\n","    for epoch in range(epochs):\n","\n","        print(f\"Training epoch {epoch}\")\n","        print(loss)\n","        for idx, entry in tqdm(enumerate(train_dataloader)):\n","            (input_tensor, carry_on, remainder) = pack_tensor(entry, input_tensor, 768)\n","\n","            if carry_on and idx != len(train_dataloader) - 1:\n","                continue\n","            input_tensor = input_tensor.to(device)\n","            outputs = model(input_tensor, labels=input_tensor)\n","            loss = outputs[0]\n","            loss.backward()\n","\n","            if (accumulating_batch_count % batch_size) == 0:\n","                optimizer.step()\n","                scheduler.step()\n","                optimizer.zero_grad()\n","                model.zero_grad()\n","\n","            accumulating_batch_count += 1\n","            input_tensor = None\n","        if save_model_on_epoch:\n","            torch.save(\n","                model.state_dict(),\n","                os.path.join(output_dir, f\"{output_prefix}-{epoch}.pt\"),\n","            )\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D9dhuz4hgKaz","executionInfo":{"status":"ok","timestamp":1666584744521,"user_tz":240,"elapsed":9538468,"user":{"displayName":"Ken Trinh","userId":"00929063106744050420"}},"outputId":"01305244-03b1-43a6-f082-fb9bf3743060"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch 0\n","0\n"]},{"output_type":"stream","name":"stderr","text":["6000it [07:53, 12.66it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch 1\n","tensor(1.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["6000it [07:57, 12.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch 2\n","tensor(2.1756, device='cuda:0', grad_fn=<NllLossBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["6000it [07:57, 12.55it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch 3\n","tensor(1.4535, device='cuda:0', grad_fn=<NllLossBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["6000it [07:57, 12.55it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch 4\n","tensor(1.6191, device='cuda:0', grad_fn=<NllLossBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["6000it [07:56, 12.60it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch 5\n","tensor(0.9957, device='cuda:0', grad_fn=<NllLossBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["6000it [07:56, 12.60it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch 6\n","tensor(1.2402, device='cuda:0', grad_fn=<NllLossBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["6000it [07:57, 12.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch 7\n","tensor(1.9769, device='cuda:0', grad_fn=<NllLossBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["6000it [07:58, 12.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch 8\n","tensor(0.5035, device='cuda:0', grad_fn=<NllLossBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["6000it [07:57, 12.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch 9\n","tensor(1.6774, device='cuda:0', grad_fn=<NllLossBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["6000it [07:56, 12.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch 10\n","tensor(2.0683, device='cuda:0', grad_fn=<NllLossBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["6000it [07:56, 12.60it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch 11\n","tensor(1.6363, device='cuda:0', grad_fn=<NllLossBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["6000it [07:56, 12.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch 12\n","tensor(1.1855, device='cuda:0', grad_fn=<NllLossBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["6000it [07:55, 12.61it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch 13\n","tensor(1.2706, device='cuda:0', grad_fn=<NllLossBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["6000it [07:55, 12.61it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch 14\n","tensor(0.8589, device='cuda:0', grad_fn=<NllLossBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["6000it [07:56, 12.60it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch 15\n","tensor(1.3278, device='cuda:0', grad_fn=<NllLossBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["6000it [07:55, 12.63it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch 16\n","tensor(1.2216, device='cuda:0', grad_fn=<NllLossBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["6000it [07:57, 12.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch 17\n","tensor(1.3418, device='cuda:0', grad_fn=<NllLossBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["6000it [07:55, 12.61it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch 18\n","tensor(0.8684, device='cuda:0', grad_fn=<NllLossBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["6000it [07:56, 12.60it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Training epoch 19\n","tensor(1.1940, device='cuda:0', grad_fn=<NllLossBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["6000it [07:57, 12.57it/s]\n"]}],"source":["model = train(dataset, model, tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hXBE62-VgKa0"},"outputs":[],"source":["torch.save(model, f'{DATA_DIR}/03_model_training/fine-tuning/rock-gpt2-fined-tuned-model.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VXKOV5XugKa0","executionInfo":{"status":"ok","timestamp":1666584752615,"user_tz":240,"elapsed":970,"user":{"displayName":"Ken Trinh","userId":"00929063106744050420"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7b06adda-936c-4a60-ade3-a24c70b176f7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model Successfully Loaded\n"]}],"source":["import torch.nn.functional as F\n","\n","#Load the model to use it in evaluation mode\n","model = torch.load(f'{DATA_DIR}/03_model_training/fine-tuning/rock-gpt2-fined-tuned-model.pt')\n","model = model.to('cpu')\n","model.eval()\n","print(\"Model Successfully Loaded\")"]},{"cell_type":"code","source":["# testing GPT fine tune with a given 16 words prompt\n","prompt = \"there's two things that i have yet to learn, how to forget or have i\"\n","\n","# tokenize the data set\n","generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n","\n","\n","# instantiate some parameters \n","top_p=0.8\n","temperature=1.\n","filter_value = -float(\"Inf\")\n","max_length = 100\n","generated_num = 0\n","generated_list = []\n","\n","\n","\n","for i in tqdm(range(max_length)):\n","\n","  # run model predict\n","  # fetch the model loss and logits(prediction outputs)\n","  outputs = model(generated, labels=generated)\n","  loss, logits = outputs[:2]\n","  logits = logits[:, -1, :] / (temperature if temperature > 0 else 1.0)\n","\n","  # apply softmax to the output logic to create a probablity\n","  sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n","  cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n","  \n","  # from the probablity, compared it with a threshold percentage (0.8) in this case\n","  # shift the sorted indicies to be removed ro the right \n","  sorted_indices_to_remove = cumulative_probs > top_p\n","  sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n","  sorted_indices_to_remove[..., 0] = False\n","\n","  # apply the filter\n","  indices_to_remove = sorted_indices[sorted_indices_to_remove]\n","  logits[:, indices_to_remove] = filter_value\n","\n","  # generate the next token and append to \n","  next_token = torch.multinomial(F.softmax(logits, dim=-1), num_samples=1)\n","  generated = torch.cat((generated, next_token), dim=1)\n","\n","  # keep text generation until the end of token is achieve\n","  # then generate the text and break out of the loop\n","  if next_token in tokenizer.encode(\"<|endoftext|>\"):\n","    generated_num = generated_num + 1\n","    output_list = list(generated.squeeze().numpy())\n","    output_text = tokenizer.decode(output_list)\n","    generated_list.append(output_text)\n","    break\n","\n","# If end of text token never reach, then just decode\n","output_list = list(generated.squeeze().numpy())\n","output_text = f\"{tokenizer.decode(output_list)}<|endoftext|>\" \n","generated_list.append(output_text)"],"metadata":{"id":"jK9xi_R3ZAHP","executionInfo":{"status":"ok","timestamp":1666584797555,"user_tz":240,"elapsed":44945,"user":{"displayName":"Ken Trinh","userId":"00929063106744050420"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bc41618a-247d-41b0-f57c-3159e0aaf9e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 100/100 [00:44<00:00,  2.23it/s]\n"]}]},{"cell_type":"code","source":["print(output_text)"],"metadata":{"id":"S5gHkHkRXXbh","executionInfo":{"status":"ok","timestamp":1666584797556,"user_tz":240,"elapsed":20,"user":{"displayName":"Ken Trinh","userId":"00929063106744050420"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"eaa10bdc-bd99-4a2e-9824-f0a7fb39de35"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["there's two things that i have yet to learn, how to forget or have i just feel something going on and what to do next. The first is knowing the laws of physics and knowing that something is wrong. The second is understanding the universe. What is happening is hard to grasp as you understand it. No one knows what is happening and every person is either on edge, confused or frightened of it. So do not trust any of the information you get as you feel you're \"coming face to face\" with reality, which is not only the reality of things, but also<|endoftext|>\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"2EhoBngxVqJC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"EJGbFcJjl-OC"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"vscode":{"interpreter":{"hash":"a4c858e9dbf5a52872cd05847dca8201cfa6512cbc8e184d871682ac09ab44b0"}},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"86f95a77c59545b4a5556c49a2cddab3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6132c7cd8b0d431d8675ca6fcbaf72b1","IPY_MODEL_aaf72408d7ce48fda2447ce011ba6804","IPY_MODEL_51a6b9e3f7004971977e5f9388e8d6c9"],"layout":"IPY_MODEL_dae77d0d6d39418c9621840ce135cff6"}},"6132c7cd8b0d431d8675ca6fcbaf72b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_34533ab31ff3434a9d6d3558fa10844f","placeholder":"​","style":"IPY_MODEL_28271993500a4d3d86ad9fdf9e2183b1","value":"Downloading: 100%"}},"aaf72408d7ce48fda2447ce011ba6804":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_58cdf13c382843eab2ea8e45be6fd3f7","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b15b060f85d441ee8ddd5e267cb87b88","value":1042301}},"51a6b9e3f7004971977e5f9388e8d6c9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_efbb0938816b46589c4584c9c96c3701","placeholder":"​","style":"IPY_MODEL_46da04d5a1914892880a1171cad35d6c","value":" 1.04M/1.04M [00:01&lt;00:00, 995kB/s]"}},"dae77d0d6d39418c9621840ce135cff6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34533ab31ff3434a9d6d3558fa10844f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28271993500a4d3d86ad9fdf9e2183b1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58cdf13c382843eab2ea8e45be6fd3f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b15b060f85d441ee8ddd5e267cb87b88":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"efbb0938816b46589c4584c9c96c3701":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46da04d5a1914892880a1171cad35d6c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad57e99e8ac34fa69e1e7fc06f21ad2c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a5bcaa9b6e4443fcb583873309932e11","IPY_MODEL_17a2fca0645d465d99ce566d241c2b9f","IPY_MODEL_6af301a7a192414784d057d8a580c29d"],"layout":"IPY_MODEL_8f97bc4de6ce4c4285700d98d43f41e4"}},"a5bcaa9b6e4443fcb583873309932e11":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_035b7c045ea04c9fb15417c059d61d60","placeholder":"​","style":"IPY_MODEL_2a0632c06de3447ba39fad06e712c411","value":"Downloading: 100%"}},"17a2fca0645d465d99ce566d241c2b9f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4214f19e99854b90b6a2f9da2bd09f62","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1303d09edaf64c02877bd3d98369c676","value":456318}},"6af301a7a192414784d057d8a580c29d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_afbb87143cf84f1dbe90836db691d563","placeholder":"​","style":"IPY_MODEL_f348b3a299334523a88265750eadb03d","value":" 456k/456k [00:01&lt;00:00, 466kB/s]"}},"8f97bc4de6ce4c4285700d98d43f41e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"035b7c045ea04c9fb15417c059d61d60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a0632c06de3447ba39fad06e712c411":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4214f19e99854b90b6a2f9da2bd09f62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1303d09edaf64c02877bd3d98369c676":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"afbb87143cf84f1dbe90836db691d563":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f348b3a299334523a88265750eadb03d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ac493df79acf47fb813030761096e053":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_17f2b2ec48bc4902afe1329fffe8c31f","IPY_MODEL_903f290e886741bd9c7cb73fe188a140","IPY_MODEL_e1c9d8b37a9346149bfad9c80c7361e2"],"layout":"IPY_MODEL_1a9d61b7e0ab4e97a118e5e08b9ce0b7"}},"17f2b2ec48bc4902afe1329fffe8c31f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_072ea81e085d4c69970876d22e7ba408","placeholder":"​","style":"IPY_MODEL_56ef7dc40952420c91653a2e23093743","value":"Downloading: 100%"}},"903f290e886741bd9c7cb73fe188a140":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ebece051889a48168e3e85a506bcf4b1","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f424a724b24044a6b6f1281b6b637d1c","value":665}},"e1c9d8b37a9346149bfad9c80c7361e2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4de79b0fa1dd4e64bec76466cb074769","placeholder":"​","style":"IPY_MODEL_ac4d22fce3bf4039844fcd455e86df7f","value":" 665/665 [00:00&lt;00:00, 6.78kB/s]"}},"1a9d61b7e0ab4e97a118e5e08b9ce0b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"072ea81e085d4c69970876d22e7ba408":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56ef7dc40952420c91653a2e23093743":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ebece051889a48168e3e85a506bcf4b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f424a724b24044a6b6f1281b6b637d1c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4de79b0fa1dd4e64bec76466cb074769":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac4d22fce3bf4039844fcd455e86df7f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b4d4e0a33e224d7fac7a603dd37a8d0a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_888ae0a7457a4fb88781d12ce7aaa741","IPY_MODEL_1bbaa6d9af16448fbdf781b9b579d344","IPY_MODEL_8d23123002f3434f8cb1bf65c58ef5f4"],"layout":"IPY_MODEL_931d6dc37d30427592027507427ebc94"}},"888ae0a7457a4fb88781d12ce7aaa741":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fe562c0e057c44169946ef6ca8e96b54","placeholder":"​","style":"IPY_MODEL_d3dce55bf3084f46be1e24ff05eb99dd","value":"Downloading: 100%"}},"1bbaa6d9af16448fbdf781b9b579d344":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad04e65a80034eaebf71d850fffc84a2","max":548118077,"min":0,"orientation":"horizontal","style":"IPY_MODEL_84c189d7fd5e4d30b33e4ed381c370b2","value":548118077}},"8d23123002f3434f8cb1bf65c58ef5f4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a073af9e77045d18b78c4cc91d9e4b6","placeholder":"​","style":"IPY_MODEL_ac5425b949924c54ba8a360ddf3603b8","value":" 548M/548M [00:09&lt;00:00, 58.1MB/s]"}},"931d6dc37d30427592027507427ebc94":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe562c0e057c44169946ef6ca8e96b54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3dce55bf3084f46be1e24ff05eb99dd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad04e65a80034eaebf71d850fffc84a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84c189d7fd5e4d30b33e4ed381c370b2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6a073af9e77045d18b78c4cc91d9e4b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac5425b949924c54ba8a360ddf3603b8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}